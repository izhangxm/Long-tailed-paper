% !TeX root = ../paper.tex

\begin{abstract}
    Long-tailed problem has been a long-standing research topic in computer vision. However, there still exists two main challenges in research of Chinese ancient text recognition task: 1) the context information significantly influences the performance of models on long-tailed datasets.  2) many existing methods lack evaluation methods specifically designed for long-tail datasets. In this paper, a context-independent data augmentation method has been proposed, which effectively alleviates the long-tail problem of ancient text recognition. This method is applied to a framework, De-ContextNet, and significantly improve model performance especially in tailed part of datasets. Specifically, words of varying lengths in a same batch are randomly concatenated together. Then the model will learn a robust representation. Furthermore, we proposed a formula for evaluating the performance of a model on long-tail datasets. Extensive experiments on three challenging Chinese ancient book datasets (TKH, MTH1000 and MTH1200) verify that our method achieves the state-of-the-art performance.\cite{zhouEastEfficientAccurate2017,zhuFourierContourEmbedding2021}
    \keywords{Open-set \and text recognition \and de-context.}
\end{abstract}
    